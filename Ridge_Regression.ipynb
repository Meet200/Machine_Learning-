{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ridge-Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpA+sNs5m8U+Fb6GBMBZdS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meet200/Machine_Learning-/blob/main/Ridge_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVBoz9r3NFO_"
      },
      "source": [
        "# Ridge Regression using Gradient Descent Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBsU9YJ4N1zG"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7hvsldoORVw"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmVXIcBSOTJK",
        "outputId": "0e4eeaba-5792-4ff9-e611-75b2e328c5a9"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUISWMqhOVKf",
        "outputId": "8f766736-55a4-4012-9edf-9d1ccb640db1"
      },
      "source": [
        "cd /content/drive/\"My Drive/Colab Notebooks/Linear regression\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Linear regression\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYc8QPRrN3nC"
      },
      "source": [
        "df = pd.read_csv(r'Behavior of the urban traffic of the city of Sao Paulo in Brazil.csv',sep=';',decimal=',')\r\n",
        "df.columns = ['Hour','Immobilized bus','Broken Truck','Vehicle excess','Accident victim','Running over','Fire vehicles','Occurrence involving freight','Incident involving dangerous freight','Lack of electricity','Fire','Point of flooding','Manifestations','Defect in the network of trolleybuses','Tree on the road','Semaphore off','Intermittent Semaphore','Slowness in traffic (%)']\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35LACWShLiUw"
      },
      "source": [
        "\r\n",
        "\r\n",
        "X_0=pd.Series([1]*len(df))\r\n",
        "X=pd.concat([X_0,df.drop(['Slowness in traffic (%)'],axis=1)],axis=1)\r\n",
        "\r\n",
        "train_size=int(round(len(df)*0.8))\r\n",
        "otpt=df['Slowness in traffic (%)']\r\n",
        "\r\n",
        "X_train=X[:train_size]\r\n",
        "X_test=X[train_size:]\r\n",
        "y_train=otpt[:train_size]\r\n",
        "y_test=otpt[train_size:]\r\n",
        "\r\n",
        "theta=np.zeros(len(X.columns))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04L-Do-DP81K",
        "outputId": "78dcef96-023b-4c16-9563-057dc95e602c"
      },
      "source": [
        "alpha=0.0001\r\n",
        "lmda=0.01\r\n",
        "n_iter=400 # by change this value and we can find the change in error and time to compile succesfful \r\n",
        "for i in range(0,n_iter):\r\n",
        "    \r\n",
        "    hx=(np.dot(X_train,theta))\r\n",
        "    theta[0]=theta[0]-((alpha*(np.sum(hx-y_train)))/108)\r\n",
        "    for j in range(1,len(theta)):\r\n",
        "        theta[j]=theta[j]*((1-(alpha*lmda))-(alpha*(np.sum(np.dot((hx-y_train),X_train.iloc[:,j])))))/108\r\n",
        "\r\n",
        "\r\n",
        "predicted_y=(np.dot(X_test,theta))\r\n",
        "error=(y_test - predicted_y)**2\r\n",
        "print(\"Error using gradient descent technique is : \",np.sum(error)/27)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error using gradient descent technique is :  132.63305183738692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlD2Qto8Q7Wg"
      },
      "source": [
        "# Ridge-Regression using standard cost optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NtR9SVEQ5CI",
        "outputId": "28f0103d-24ca-4f3f-c357-4dfbd3b24b07"
      },
      "source": [
        "XT=np.transpose(X_train)\r\n",
        "XTX=np.dot(XT,X_train)\r\n",
        "Ident_M=np.identity(18)\r\n",
        "lmda=0.01\r\n",
        "RIXTX=np.linalg.inv(XTX+(lmda*Ident_M))\r\n",
        "theta=np.dot(RIXTX,np.dot(XT,y_train))\r\n",
        "predic_y = np.dot(X_test,theta)\r\n",
        "error=(y_test - predic_y)\r\n",
        "print(\"Error using standard cost optimization is : \",np.sum(error)/27)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error using standard cost optimization is :  2.6251971520719706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR5Uk0HmRPTT"
      },
      "source": [
        "Here it is clearly observed that by using gradient descent method we need number of iteration too High and it will take too much time to compile code we can see that variation by changing value of theta, while in eqation optimization technique it is very easy and does not need to much time to compute."
      ]
    }
  ]
}